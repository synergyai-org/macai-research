{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "use_gpu = '5' # kimbg\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = use_gpu \n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":16:8\"\n",
    "\n",
    "import sys\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# pd.set_option('display.max_columns', None)  # 최대 100개 열 표시x\n",
    "# pd.set_option('display.max_colwidth', None)  # 열 너비 제한 해제\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.amp as amp\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_architecture import SynAI\n",
    "from processing import utils, dataset, transforms\n",
    "from trainer import train_engine, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    ###--- Genernal Settings ---###\n",
    "    seed = 0 ; utils.SetSeedEverything(seed, fully_deterministic=True)\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    use_amp = torch.cuda.is_available()\n",
    "    amp_scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "    num_workers = 4\n",
    "    papermill = False\n",
    "    model_auto_remove = False\n",
    "\n",
    "\n",
    "    ###--- Main Config. ---###\n",
    "    CurStep = 3  # {3: ECG-labeled prediction}\n",
    "    model_save_root_path = '/mnt/home/bgk/macai-model-experimental/_kimbg_code/SynAI_v2/outputs/checkpoint'\n",
    "    model_dir_name = f'CL_step{CurStep}-TRN-MacAI_v1_2-0822'\n",
    "    model_save_path = os.path.join(model_save_root_path, model_dir_name)\n",
    "    os.makedirs(model_save_path, exist_ok=True)\n",
    "\n",
    "\n",
    "    ###--- Dataset Load ---###\n",
    "    dataset_fraction = 1 # 0~1 if False: fully use\n",
    "    interest_windows = [14]  # [3,7,14,30,90,180,365]\n",
    "    add_status = False\n",
    "\n",
    "    target_cols = {'input':'bpf0540_or3-npy_path',}\n",
    "    subset_cols = [target_cols['input']] + ['kfold']\n",
    "\n",
    "    # if CurStep == 4:\n",
    "    #     pass    \n",
    "    if CurStep == 3:\n",
    "        # target_class_list = ['AFIB_AFL-keyword_v2', 'CIA-keyword_v2', 'AA-keyword_v2', 'VP-keyword_v2', 'BBB-keyword_v2']\n",
    "        target_class_list = ['AFIB_AFL-keyword_v2', 'CIA-keyword_v2']\n",
    "        target_cols['label'] = []\n",
    "        for window in interest_windows:\n",
    "            for target_class in target_class_list:\n",
    "                target_cols['label'] += [f'ECG_event_{window}d_{target_class}_onset']\n",
    "        if add_status: \n",
    "            target_cols['label'] += target_class_list[:]\n",
    "        subset_cols += target_cols['label']\n",
    "        dataset_df_path = '/home/Datasets_processed/EKG_Latest/processed_metadata_v6-sv2_subset_2_holdin.csv'\n",
    "        test_dataset_df_path = '/home/Datasets_processed/EKG_Latest/processed_metadata_v6-sv2_subset_2_holdout.csv'\n",
    "        # public_trn_dataset_df_path = '/home/Datasets_processed/BenchmarkSets/MIMIC_IV_ECG/preprocessed_v6-trn.csv'\n",
    "        public_trn_dataset_df_path = None\n",
    "        public_val_dataset_df_path = '/home/Datasets_processed/BenchmarkSets/MIMIC_IV_ECG/preprocessed_v6-val.csv'\n",
    "        # public_val_dataset_df_path = None\n",
    "        # snuh_trn_dataset_df_path = '/home/Datasets_processed/EKG_Latest/SNUH/metadata_v4-ms_v2-trn.csv'\n",
    "        snuh_trn_dataset_df_path = None\n",
    "        snuh_val_dataset_df_path = '/home/Datasets_processed/EKG_Latest/SNUH/metadata_v4-ms_v2-val.csv'\n",
    "        target_fold_list = [0]  # [0,2,4,6,8]\n",
    "        n_folds, trn_ratio, val_ratio = 10, 9, 1\n",
    "        weighted_random_sampler = 'pid_log_weight'  # pid_log_weight, pid_weight\n",
    "        if weighted_random_sampler:\n",
    "            subset_cols.append(weighted_random_sampler)\n",
    "        model_auto_remove = True\n",
    "\n",
    "    if CurStep == 2:\n",
    "        target_cols['label'] = ['AFIB_AFL-keyword_v2', 'CIA-keyword_v2']\n",
    "        subset_cols += target_cols['label']\n",
    "        dataset_df_path = '/home/Datasets_processed/EKG_Latest/processed_metadata_v6-subset_1.csv'\n",
    "        test_dataset_df_path = None\n",
    "        # public_trn_dataset_df_path = '/home/Datasets_processed/BenchmarkSets/MIMIC_IV_ECG/preprocessed_v6-subset_1_trn.csv'\n",
    "        public_trn_dataset_df_path = None\n",
    "        # public_val_dataset_df_path = '/home/Datasets_processed/BenchmarkSets/MIMIC_IV_ECG/preprocessed_v6-subset_1_val.csv'\n",
    "        public_val_dataset_df_path = None\n",
    "        target_fold_list = [0]  # [0,2,4,6,8]\n",
    "        n_folds, trn_ratio, val_ratio = 10, 9, 1\n",
    "        weighted_random_sampler = 'pid_log_weight'  # pid_log_weight, pid_weight\n",
    "        if weighted_random_sampler:\n",
    "            subset_cols.append(weighted_random_sampler)\n",
    "        model_auto_remove = True\n",
    "        \n",
    "    filter_col = target_cols['label'][-1]\n",
    "    print('filter_col : ', filter_col)\n",
    "    print('subset_cols : ', subset_cols)\n",
    "    def df_read_and_filtering(df_path, filter_col, subset_cols, prefix = None):\n",
    "        df = pd.read_csv(df_path)\n",
    "        print(f'Original {prefix} dataframe shape : {df.shape}')\n",
    "        con = (df[filter_col].isin([0,1]))\n",
    "        df = df[con].reset_index(drop=True)[subset_cols].copy()\n",
    "        print(f'Filtered {prefix} dataframe shape : {df.shape}') \n",
    "        return df\n",
    "    \n",
    "    dataset_df = df_read_and_filtering(dataset_df_path, filter_col, subset_cols, prefix = 'EUMC-trn-set')\n",
    "    if test_dataset_df_path:\n",
    "        test_dataset_df = df_read_and_filtering(test_dataset_df_path, filter_col, subset_cols, prefix = 'EUMC-tst-set')\n",
    "    if public_trn_dataset_df_path:\n",
    "        public_trn_dataset_df = df_read_and_filtering(public_trn_dataset_df_path, filter_col, subset_cols, prefix = 'BIDMC-trn-set')\n",
    "        dataset_df = pd.concat([dataset_df, public_trn_dataset_df], axis=0).reset_index(drop=True)\n",
    "    if public_val_dataset_df_path:\n",
    "        public_val_dataset_df = df_read_and_filtering(public_val_dataset_df_path, filter_col, subset_cols, prefix = 'BIDMC-tst-set')\n",
    "    if snuh_trn_dataset_df_path:\n",
    "        snuh_trn_dataset_df = df_read_and_filtering(snuh_trn_dataset_df_path, filter_col, subset_cols, prefix = 'SNUH-trn-set')\n",
    "        dataset_df = pd.concat([dataset_df, snuh_trn_dataset_df], axis=0).reset_index(drop=True)\n",
    "    if snuh_val_dataset_df_path:\n",
    "        snuh_val_dataset_df = df_read_and_filtering(snuh_val_dataset_df_path, filter_col, subset_cols, prefix = 'SNUH-tst-set')\n",
    "    print(f'*** FINAL TRAIN dataframe shape *** : {dataset_df.shape}')\n",
    "\n",
    "\n",
    "    ###--- Data Input Config. ---###\n",
    "    input_config = {\n",
    "        'seq_length':2560, 'in_channels':12, 'num_classes':len(target_cols['label']),\n",
    "        'target_lead':'12lead'  # I, II, III, aVR, aVL, aVF, V1, V2, V3, V4, V5, V6, limb, precordial, 12lead\n",
    "    }\n",
    "\n",
    "\n",
    "    ###--- Model Architecture ---###\n",
    "    model_architecture = SynAI.Build_Model_250526\n",
    "    model_info = {\n",
    "        #--- meta ---#\n",
    "        'mode':'finetuning',  # finetuning, pretraining\n",
    "        'weights_init':'SSL_transfer',  # scratch, SSL_transfer, DST_transfer\n",
    "\n",
    "        #--- SynAI config ---#\n",
    "        'name':'MAE_1D_250409_v3',\n",
    "        'config':{\n",
    "            'embed_dim':768,  # 384 768\n",
    "            'patch_size':32, \n",
    "            'seq_length':input_config['seq_length'],\n",
    "            'in_channels':input_config['in_channels'], \n",
    "            'encoder':'vit_encoder',\n",
    "            'merge_mode':'projection',  # linear_projection avg add\n",
    "            #--- for self-supervised learning ---#\n",
    "            'decoder_depth':2, \n",
    "            'decoder_num_heads':8,\n",
    "            'stft_loss_ratio':0,\n",
    "        }\n",
    "    }\n",
    "    if model_info['mode'] == 'finetuning':\n",
    "        model_info['config'].update({'num_classes':input_config['num_classes']})\n",
    "    if 'transfer' in model_info['weights_init']:\n",
    "        model_info['prev_model_path'] = os.path.join(\n",
    "            '/home/bgk/macai-model-experimental/checkpoint',\n",
    "            'Step1-TRN_VAL-0526/Best_loss-Ep_550-Lo_0.0020.pth'\n",
    "        )\n",
    "\n",
    "\n",
    "    ###--- Modeling Options ---###\n",
    "    batch_size = 512\n",
    "    epoch = 30\n",
    "    valid_interval = 1 # 10\n",
    "    early_stopping_patience = 5\n",
    "    early_stopping_mode = 'max' # 'min' -> loss, 'max' -> main_metric\n",
    "    start_lr, final_lr = 2e-4, 1e-5\n",
    "    start_factor, warmup = 1, 0.05\n",
    "    scheduler_lr = True # True\n",
    "    clip_grad_norm = 1.0\n",
    "    early_stopping = utils.EarlyStopping\n",
    "    \n",
    "\n",
    "    ###--- Loss Functions & Metrics ---###\n",
    "    pos_weight = None\n",
    "    if pos_weight:\n",
    "        train_labels = torch.tensor(dataset_df[target_cols['label']].values)\n",
    "        class_counts_pos = (train_labels == 1).sum(dim=0)\n",
    "        class_counts_neg = (train_labels == 0).sum(dim=0)\n",
    "        class_counts_pos = class_counts_pos.float() + 1e-8  # epsilon\n",
    "        class_counts_neg = class_counts_neg.float() + 1e-8  # epsilon\n",
    "        pos_weight = torch.tensor(class_counts_neg / class_counts_pos, device=device)\n",
    "        pos_weight = pos_weight / pos_weight.mean()\n",
    "    print(f\"계산된 pos_weight: {pos_weight}\")\n",
    "\n",
    "    task_weights = []\n",
    "    pri_task_w, aux_task_w = 1, 0.1\n",
    "    for iw in interest_windows:\n",
    "        if iw == 14:\n",
    "            task_weights += [pri_task_w,]*2\n",
    "        else:\n",
    "            task_weights += [aux_task_w,]*2\n",
    "    if add_status:\n",
    "        task_weights += [aux_task_w,]*2\n",
    "    task_weights = torch.tensor(task_weights, device=device)\n",
    "    print(f\"계산된 task_weights: {task_weights}\")\n",
    "\n",
    "    loss_fn = losses.AuxFocalSmoothBCELoss(pos_weight=pos_weight, task_weights=task_weights, gamma=0, smoothing=0.1)\n",
    "\n",
    "\n",
    "    #--- Transforms ---#\n",
    "    transforms_config = {}\n",
    "    transforms_config['NormalizeECG'] = {'method':\"tanh\", 'scope':\"lead-wise\", 'scale':1}\n",
    "    transforms_config['RandomLeadSwapping'] = {'swap_ratio':0.5, 'swap_pairs':None, 'p':0.25}    \n",
    "    # transforms_config['ApplyGaussianNoise(add_per_lead)'] = {'noise_level': 0.1, 'mode': 'add', 'per_lead': True, 'p':0.5}\n",
    "    # transforms_config['ApplyGaussianNoise(mul_per_lead)'] = {'noise_level': 0.05, 'mode': 'mul', 'per_lead': True, 'p':0.5}\n",
    "    # transforms_config['ApplySinusoidalNoise(baseline_drift)'] = {\n",
    "    #     'frequency_range': (0.1, 1), 'amplitude_range': (0.01, 0.1), 'mode':'add', 'per_lead': False, 'p':0.5}\n",
    "    # transforms_config['ApplySinusoidalNoise(EMG)'] = {\n",
    "    #     'frequency_range': (30, 100), 'amplitude_range': (0.01, 0.1), 'mode':'add', 'per_lead': True, 'p':0.5}\n",
    "    # transforms_config['ApplySinusoidalNoise(powerline_noise)'] = {\n",
    "    #     'frequency_range': (50,60), 'amplitude_range': (0.01, 0.1), 'mode':'add', 'per_lead': False, 'p':0.5}\n",
    "    transforms_config['AddTimeWarp'] = {'warp_factor_range':(0.75, 1.25), 'padding_mode':\"repeat\", 'p':0.25}\n",
    "    transforms_config['RandomLeadMasking'] = {'mask_ratio':0.5, 'mask_leads':None, 'p':0.25}\n",
    "    transforms_list = [\n",
    "        getattr(transforms, key.split('(')[0])(**params)\n",
    "        for key, params in transforms_config.items()\n",
    "    ]\n",
    "    transform_pipeline_dict = {}\n",
    "    transform_pipeline_dict['train'] = transforms.TransformPipeline(transforms_list)\n",
    "    transform_pipeline_dict['val'] = transforms.TransformPipeline(transforms_list[:1])  # only scaling\n",
    "\n",
    "\n",
    "    ###--- check gpu ---###\n",
    "    if torch.cuda.is_available(): print(f\"CUDA is available. GPU No.{use_gpu}\")\n",
    "    else: print(\"CUDA is not available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For papermill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # param_dict would be defined from papermill\n",
    "\n",
    "# if CFG.papermill:\n",
    "#     for k, v in param_dict.items():\n",
    "#         if k in ['batch_size', 'start_lr']:\n",
    "#             setattr(CFG, f'{k}', v)  # 'k'라는 속성을 동적으로 추가\n",
    "#             print(k, CFG.__dict__[f'{k}'])\n",
    "            \n",
    "#         elif k == 'model_dir_name':\n",
    "#             setattr(CFG, f'{k}', v)  # 'k'라는 속성을 동적으로 추가\n",
    "#             CFG.model_save_path = os.path.join(CFG.model_save_root_path, CFG.model_dir_name)\n",
    "#             os.makedirs(CFG.model_save_path, exist_ok=True)\n",
    "#             print(k, CFG.__dict__[f'{k}'])\n",
    "\n",
    "#         elif k == 'transforms_config':\n",
    "#             setattr(CFG, f'{k}', v)  # 'k'라는 속성을 동적으로 추가\n",
    "#             transforms_list = [\n",
    "#                 getattr(_kimbg_transforms, key.split('(')[0])(**params)\n",
    "#                 for key, params in CFG.transforms_config.items()\n",
    "#             ]\n",
    "#             CFG.transform_pipeline = _kimbg_transforms.TransformPipeline(transforms_list)\n",
    "#             print('transforms_config', CFG.transforms_config)\n",
    "\n",
    "#         elif k == 'interest_windows':\n",
    "#             setattr(CFG, f'{k}', v)  # 'k'라는 속성을 동적으로 추가\n",
    "#             CFG.interest_windows = [v]\n",
    "#             CFG.label_col = [f'label_ECG_AFIB_AFL_within_{i}d' for i in CFG.interest_windows]\n",
    "#             CFG.target_cols = {\n",
    "#                 'input':'bpf0540_or3-npy_path', 'label':CFG.label_col\n",
    "#             }\n",
    "#             CFG.dataset_df_path = \"/home/Datasets_processed/raw_ECGs/meta_log_v8-labelled_fold-S2.csv\"\n",
    "#             CFG.dataset_df = pd.read_csv(CFG.dataset_df_path)\n",
    "#             print(f'Original DataFrame shape : {CFG.dataset_df.shape}')\n",
    "#             con1 = (CFG.dataset_df[CFG.label_col[-1]]!=-1)\n",
    "#             CFG.dataset_df = CFG.dataset_df[con1].reset_index(drop=True)\n",
    "#             print(f'Filtered DataFrame shape (after removing no_label) : {CFG.dataset_df.shape}')\n",
    "\n",
    "#             # Dataset Matched with Holter Label\n",
    "#             CFG.holter_dataset_df_path = \"/home/Datasets_processed/raw_ECGs/meta_log_v8-labelled_fold-S3.csv\"\n",
    "#             CFG.holter_label_col = [f'label_holter_AFIB_AFL_within_{i}d' for i in CFG.interest_windows]\n",
    "#             CFG.holter_target_cols = {\n",
    "#                 'input':'bpf0540_or3-npy_path', 'label':CFG.holter_label_col\n",
    "#             }\n",
    "#             CFG.holter_dataset_df = pd.read_csv(CFG.holter_dataset_df_path)\n",
    "#             print(f'Original holter_dataset_df shape : {CFG.holter_dataset_df.shape}')\n",
    "#             holter_con1 = (CFG.holter_dataset_df[CFG.holter_label_col[-1]]!=-1)\n",
    "#             CFG.holter_dataset_df = CFG.holter_dataset_df[holter_con1].reset_index(drop=True)\n",
    "#             print(f'Filtered holter_dataset_df shape (after removing no_label) : {CFG.holter_dataset_df.shape}')\n",
    "            \n",
    "#         else:\n",
    "#             CFG.model_info[f'{k}'] = v\n",
    "#             print(k, CFG.model_info[f'{k}'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model name : MAE_1D_250409_v3\n",
      "seq_length 2560, in_channels 12, patch_size 32, embed_dim 768, token_len 80, \n",
      "model was loaded from '/home/bgk/macai-model-experimental/checkpoint/Step1-TRN_VAL-0526/Best_loss-Ep_550-Lo_0.0020.pth'\n",
      "Model Parameter Count: 113.34M\n"
     ]
    }
   ],
   "source": [
    "model = CFG.model_architecture(CFG.model_info).to(CFG.device)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model Parameter Count: {total_params*1e-6:.2f}M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataframe shape: (50026, 5), dataloader length: 97\n",
      "val dataframe shape: (5453, 5), dataloader length: 11\n",
      "test dataframe shape: (15190, 5), dataloader length: 30\n",
      "pub_test dataframe shape: (20060, 5), dataloader length: 40\n",
      "snuh_test dataframe shape: (31776, 5), dataloader length: 63\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sample path: /home/Datasets_processed/EKG_Latest/signal-bpf0540_or3/20170721201048_0664F020_0000_20170721192615_11324604.npy\n",
      "torch.Size([512, 12, 2560]), dtype: torch.float32, max: 1.0000, min: -1.0000, mean: 0.0173, std: 0.4324\n",
      "val sample path: /home/Datasets_processed/EKG_Latest/signal-bpf0540_or3/14898871_2021-11-17_2021111719451618_2021111719452386.npy\n",
      "torch.Size([512, 12, 2560]), dtype: torch.float32, max: 1.0000, min: -1.0000, mean: 0.0203, std: 0.4602\n",
      "test sample path: /home/Datasets_processed/EKG_Latest/signal-bpf0540_or3/10302870_2023-10-17_2023101716092374_2023101716095795.npy\n",
      "torch.Size([512, 12, 2560]), dtype: torch.float32, max: 1.0000, min: -1.0000, mean: 0.0172, std: 0.4635\n",
      "pub_test sample path: /home/Datasets_processed/BenchmarkSets/MIMIC_IV_ECG/npys-bpf0540_or3/10001186/10001186_45986118.npy\n",
      "torch.Size([512, 12, 2560]), dtype: torch.float32, max: 1.0000, min: -1.0000, mean: 0.0188, std: 0.4738\n",
      "snuh_test sample path: /home/Datasets_processed/EKG_Latest/SNUH/signal-bpf0540_or3/ECG_idx_00000023-PID_R-1448-00000006.npy\n",
      "torch.Size([512, 12, 2560]), dtype: torch.float32, max: 1.0000, min: -1.0000, mean: 0.0186, std: 0.4599\n"
     ]
    }
   ],
   "source": [
    "fold_data_dict = {}\n",
    "\n",
    "for fold_idx, target_fold in enumerate(CFG.target_fold_list):\n",
    "\n",
    "    #--- 기본 fold 지정 ---#\n",
    "    fold_dict = {\n",
    "        'train_fold': [x % CFG.n_folds for x in range(target_fold, target_fold + CFG.trn_ratio)],\n",
    "        'val_fold': [x % CFG.n_folds for x in range(\n",
    "            target_fold + CFG.trn_ratio, target_fold + CFG.trn_ratio + CFG.val_ratio)],\n",
    "    }\n",
    "\n",
    "    #--- dataframe 생성 ---#\n",
    "    df_dict = {}\n",
    "    for split in ['train', 'val']:\n",
    "        split_folds = fold_dict[f'{split}_fold']\n",
    "        df  = CFG.dataset_df[CFG.dataset_df['kfold'].isin(split_folds)]\n",
    "        if split == 'train' and (0 < CFG.dataset_fraction < 1):\n",
    "            df = df.sample(frac=CFG.dataset_fraction, random_state=CFG.seed+831, ignore_index=True)\n",
    "        df_dict[split] = df\n",
    "    if CFG.test_dataset_df_path:\n",
    "        df_dict['test'] = CFG.test_dataset_df\n",
    "    if CFG.public_val_dataset_df_path:\n",
    "        df_dict['pub_test'] = CFG.public_val_dataset_df\n",
    "    if CFG.snuh_val_dataset_df_path:\n",
    "        df_dict['snuh_test'] = CFG.snuh_val_dataset_df\n",
    "\n",
    "    #--- dataset 생성 ---#\n",
    "    dataset_dict = {}\n",
    "    for split in df_dict.keys():\n",
    "        # dataset_dict[split] = dataset.DatasetFromDataframe(\n",
    "        dataset_dict[split] = dataset.DatasetFromDataframe_v2(\n",
    "            df          = df_dict[split],\n",
    "            input_col   = CFG.target_cols['input'],\n",
    "            label_col   = CFG.target_cols['label'],\n",
    "            target_len  = CFG.input_config['seq_length'],\n",
    "            target_lead = CFG.input_config['target_lead'],\n",
    "            transforms  = CFG.transform_pipeline_dict['train'] if split == 'train' else CFG.transform_pipeline_dict['val'],\n",
    "        )\n",
    "\n",
    "    #--- 샘플러 설정 ---#\n",
    "    sampler = None\n",
    "    if CFG.weighted_random_sampler:\n",
    "        sampler = WeightedRandomSampler(\n",
    "            weights     = df_dict['train'][CFG.weighted_random_sampler].values,\n",
    "            num_samples = len(dataset_dict['train']),\n",
    "            replacement = True\n",
    "        )\n",
    "\n",
    "    #--- dataloader 생성 ---#\n",
    "    dataloader_dict = {}\n",
    "    for split in df_dict.keys():\n",
    "        dataloader_dict[split] = DataLoader(\n",
    "            dataset            = dataset_dict[split],\n",
    "            batch_size         = CFG.batch_size,\n",
    "            shuffle            = (split == 'train') and not CFG.weighted_random_sampler,\n",
    "            sampler            = sampler if split == 'train' else None,\n",
    "            num_workers        = CFG.num_workers,\n",
    "            pin_memory         = True,\n",
    "            drop_last          = (split == 'train'),\n",
    "            persistent_workers = (CFG.num_workers != 0),\n",
    "            prefetch_factor    = (CFG.num_workers // 4) if CFG.num_workers != 0 else None,\n",
    "        )\n",
    "\n",
    "    # fold 결과 저장\n",
    "    fold_data_dict[fold_idx] = {\n",
    "        'fold_dict'      : fold_dict,\n",
    "        'df_dict'        : df_dict,\n",
    "        'dataset_dict'   : dataset_dict,\n",
    "        'dataloader_dict': dataloader_dict,\n",
    "    }\n",
    "\n",
    "# 체크 로그\n",
    "for split in df_dict.keys():\n",
    "    print(f'{split} dataframe shape: {df_dict[split].shape}, dataloader length: {len(dataloader_dict[split])}')\n",
    "print()\n",
    "for split in df_dict.keys():\n",
    "    sample = next(iter(dataloader_dict[split]))\n",
    "    print(f'{split} sample path: {sample[\"input_path\"][0]}')\n",
    "    print(\n",
    "        f'{sample[\"input\"].shape}, dtype: {sample[\"input\"].dtype}, '\n",
    "        f'max: {torch.max(sample[\"input\"]):.4f}, min: {torch.min(sample[\"input\"]):.4f}, '\n",
    "        f'mean: {torch.mean(sample[\"input\"]):.4f}, std: {torch.std(sample[\"input\"]):.4f}'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model name : MAE_1D_250409_v3\n",
      "seq_length 2560, in_channels 12, patch_size 32, embed_dim 768, token_len 80, \n",
      "model was loaded from '/home/bgk/macai-model-experimental/checkpoint/Step1-TRN_VAL-0526/Best_loss-Ep_550-Lo_0.0020.pth'\n",
      "Training will start from epoch 0\n",
      "\n",
      "||| Current epoch: 0 |||\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/97 [00:00<?, ?it/s]/opt/conda/envs/250424_cp/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      "| TRN | batch loss : 0.4321, lr : 2.0e-04 :  99%|█████████▉| 96/97 [01:30<00:00,  1.12it/s]/opt/conda/envs/250424_cp/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "| TRN | batch loss : 0.4052, lr : 2.0e-04 : 100%|██████████| 97/97 [01:31<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| TRN-Avg. | loss : 0.480, AUROC : 0.65, AUPRC : 0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| VAL | batch loss: 0.5139, : 100%|██████████| 11/11 [00:09<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| VAL-Avg. | loss : 0.471, AUROC : 0.748, AUPRC : 0.406\n",
      "*** Best Record! ***\n",
      "- Improved loss: inf → 0.4712\n",
      "- Improved AUROC: -1.0000 → 0.7477\n",
      "- Improved AUPRC: -1.0000 → 0.4056\n",
      "Saved at /home/bgk/macai-model-experimental/_kimbg_code/SynAI_v2/outputs/checkpoint/CL_step3-TRN-MacAI_v1_2-0822/0fold/Best_loss-Ep_0-Lo_0.471-M0_0.748-M1_0.406.pth\n",
      "Saved at /home/bgk/macai-model-experimental/_kimbg_code/SynAI_v2/outputs/checkpoint/CL_step3-TRN-MacAI_v1_2-0822/0fold/Best_AUROC-Ep_0-Lo_0.471-M0_0.748-M1_0.406.pth\n",
      "Saved at /home/bgk/macai-model-experimental/_kimbg_code/SynAI_v2/outputs/checkpoint/CL_step3-TRN-MacAI_v1_2-0822/0fold/Best_AUPRC-Ep_0-Lo_0.471-M0_0.748-M1_0.406.pth\n",
      "[EarlyStopping] (Update) Best Score: 0.74775\n",
      "\n",
      "||| Current epoch: 1 |||\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| TRN | batch loss : 0.3952, lr : 2.0e-04 : 100%|██████████| 97/97 [02:01<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| TRN-Avg. | loss : 0.419, AUROC : 0.75, AUPRC : 0.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| VAL | batch loss: 0.5085, : 100%|██████████| 11/11 [00:09<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| VAL-Avg. | loss : 0.462, AUROC : 0.754, AUPRC : 0.417\n",
      "*** Best Record! ***\n",
      "- Improved loss: 0.4712 → 0.4619\n",
      "- Improved AUROC: 0.7477 → 0.7544\n",
      "- Improved AUPRC: 0.4056 → 0.4170\n",
      "Saved at /home/bgk/macai-model-experimental/_kimbg_code/SynAI_v2/outputs/checkpoint/CL_step3-TRN-MacAI_v1_2-0822/0fold/Best_loss-Ep_1-Lo_0.462-M0_0.754-M1_0.417.pth\n",
      "Saved at /home/bgk/macai-model-experimental/_kimbg_code/SynAI_v2/outputs/checkpoint/CL_step3-TRN-MacAI_v1_2-0822/0fold/Best_AUROC-Ep_1-Lo_0.462-M0_0.754-M1_0.417.pth\n",
      "Saved at /home/bgk/macai-model-experimental/_kimbg_code/SynAI_v2/outputs/checkpoint/CL_step3-TRN-MacAI_v1_2-0822/0fold/Best_AUPRC-Ep_1-Lo_0.462-M0_0.754-M1_0.417.pth\n",
      "[EarlyStopping] (Update) Best Score: 0.75442\n",
      "\n",
      "||| Current epoch: 2 |||\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| TRN | batch loss : 0.4053, lr : 2.0e-04 : 100%|██████████| 97/97 [01:49<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| TRN-Avg. | loss : 0.412, AUROC : 0.77, AUPRC : 0.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| VAL | batch loss: 0.5056, : 100%|██████████| 11/11 [00:08<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| VAL-Avg. | loss : 0.462, AUROC : 0.758, AUPRC : 0.421\n",
      "*** Best Record! ***\n",
      "- Improved loss: 0.4619 → 0.4617\n",
      "- Improved AUROC: 0.7544 → 0.7581\n",
      "- Improved AUPRC: 0.4170 → 0.4214\n",
      "Saved at /home/bgk/macai-model-experimental/_kimbg_code/SynAI_v2/outputs/checkpoint/CL_step3-TRN-MacAI_v1_2-0822/0fold/Best_loss-Ep_2-Lo_0.462-M0_0.758-M1_0.421.pth\n",
      "Saved at /home/bgk/macai-model-experimental/_kimbg_code/SynAI_v2/outputs/checkpoint/CL_step3-TRN-MacAI_v1_2-0822/0fold/Best_AUROC-Ep_2-Lo_0.462-M0_0.758-M1_0.421.pth\n",
      "Saved at /home/bgk/macai-model-experimental/_kimbg_code/SynAI_v2/outputs/checkpoint/CL_step3-TRN-MacAI_v1_2-0822/0fold/Best_AUPRC-Ep_2-Lo_0.462-M0_0.758-M1_0.421.pth\n",
      "[EarlyStopping] (Update) Best Score: 0.75810\n",
      "\n",
      "||| Current epoch: 3 |||\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| TRN | batch loss : 0.3902, lr : 2.0e-04 : 100%|██████████| 97/97 [01:26<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| TRN-Avg. | loss : 0.407, AUROC : 0.79, AUPRC : 0.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| VAL | batch loss: 0.5086, : 100%|██████████| 11/11 [00:09<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| VAL-Avg. | loss : 0.463, AUROC : 0.754, AUPRC : 0.416\n",
      "[EarlyStopping] (Patience) 1/5, Best: 0.75810, Current: 0.75375, Delta: 0.00435\n",
      "\n",
      "||| Current epoch: 4 |||\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| TRN | batch loss : 0.4045, lr : 1.9e-04 : 100%|██████████| 97/97 [01:28<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| TRN-Avg. | loss : 0.401, AUROC : 0.80, AUPRC : 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| VAL | batch loss: 0.5146, : 100%|██████████| 11/11 [00:09<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| VAL-Avg. | loss : 0.475, AUROC : 0.755, AUPRC : 0.415\n",
      "[EarlyStopping] (Patience) 2/5, Best: 0.75810, Current: 0.75522, Delta: 0.00288\n",
      "\n",
      "||| Current epoch: 5 |||\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| TRN | batch loss : 0.3954, lr : 1.9e-04 : 100%|██████████| 97/97 [01:29<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| TRN-Avg. | loss : 0.393, AUROC : 0.82, AUPRC : 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| VAL | batch loss: 0.5579, : 100%|██████████| 11/11 [00:10<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| VAL-Avg. | loss : 0.492, AUROC : 0.740, AUPRC : 0.392\n",
      "[EarlyStopping] (Patience) 3/5, Best: 0.75810, Current: 0.73977, Delta: 0.01832\n",
      "\n",
      "||| Current epoch: 6 |||\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| TRN | batch loss : 0.3751, lr : 1.8e-04 : 100%|██████████| 97/97 [01:27<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| TRN-Avg. | loss : 0.383, AUROC : 0.84, AUPRC : 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| VAL | batch loss: 0.5311, : 100%|██████████| 11/11 [00:08<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| VAL-Avg. | loss : 0.491, AUROC : 0.736, AUPRC : 0.386\n",
      "[EarlyStopping] (Patience) 4/5, Best: 0.75810, Current: 0.73625, Delta: 0.02184\n",
      "\n",
      "||| Current epoch: 7 |||\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| TRN | batch loss : 0.3635, lr : 1.7e-04 : 100%|██████████| 97/97 [01:26<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| TRN-Avg. | loss : 0.373, AUROC : 0.86, AUPRC : 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| VAL | batch loss: 0.5371, : 100%|██████████| 11/11 [00:09<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| VAL-Avg. | loss : 0.496, AUROC : 0.737, AUPRC : 0.387\n",
      "[EarlyStopping] (Patience) 5/5, Best: 0.75810, Current: 0.73711, Delta: 0.02099\n",
      "[EarlyStop Triggered] Best Score: 0.75810\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "for fold_idx, target_fold in enumerate(CFG.target_fold_list):\n",
    "    \n",
    "    #--- 경로 및 초기 설정 ---#\n",
    "    model_fold_path = os.path.join(CFG.model_save_path, f'{target_fold}fold')\n",
    "    os.makedirs(model_fold_path, exist_ok=True)\n",
    "    \n",
    "\n",
    "    #--- EarlyStopping 인스턴스 초기화 ---#\n",
    "    early_stopping = CFG.early_stopping(patience = CFG.early_stopping_patience,\n",
    "                                        delta    = 0,\n",
    "                                        mode     = CFG.early_stopping_mode,\n",
    "                                        verbose  = True\n",
    "    )\n",
    "\n",
    "    #--- Best 기록 초기화 ---#\n",
    "    BEST_RECORD_DICT = {'record_df'               : pd.DataFrame(),\n",
    "                        'epoch'                   : -1,\n",
    "                        'best_loss'               : float('inf'),\n",
    "                        'best_AUROC'              : -1,\n",
    "                        'best_AUPRC'              : -1,\n",
    "                        'best_loss_ckp_path'      : None,\n",
    "                        'best_AUROC_ckp_path'     : None,\n",
    "                        'best_AUPRC_ckp_path'     : None,\n",
    "    }\n",
    "\n",
    "\n",
    "    #--- 모델 구성 ---#\n",
    "    model = CFG.model_architecture(CFG.model_info).to(CFG.device)\n",
    "\n",
    "\n",
    "    #--- Optimizer & Scheduler ---#\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=CFG.start_lr)\n",
    "    scheduler_dict = {'lr': None}\n",
    "    if CFG.scheduler_lr:\n",
    "        steps_per_epoch = len(fold_data_dict[fold_idx]['dataloader_dict']['train'])\n",
    "        num_training_steps = CFG.epoch * steps_per_epoch\n",
    "        num_warmup_steps = int(CFG.epoch * CFG.warmup) * steps_per_epoch\n",
    "        num_cosine_steps = num_training_steps - num_warmup_steps\n",
    "        warmup_scheduler = lr_scheduler.LinearLR(\n",
    "            optimizer, start_factor = CFG.start_factor, end_factor = 1.0, total_iters = num_warmup_steps)\n",
    "        cosine_scheduler = lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer, T_max = num_cosine_steps, eta_min = CFG.final_lr)\n",
    "        scheduler_dict['lr'] = lr_scheduler.SequentialLR(\n",
    "            optimizer, schedulers = [warmup_scheduler, cosine_scheduler],\n",
    "            milestones = [num_warmup_steps])\n",
    "    start_epoch = 0\n",
    "    print(f\"Training will start from epoch {0}\")\n",
    "\n",
    "\n",
    "    # ------------------------------------------------------------------------------------ # \n",
    "    # ------------------------------------------------------------------------------------ # \n",
    "    # ------------------------------------------------------------------------------------ # \n",
    "    \n",
    "    \n",
    "    #--- Model Training Loop ---#\n",
    "    for epoch in range(start_epoch, CFG.epoch):\n",
    "        print(f'\\n||| Current epoch: {epoch} |||')\n",
    "\n",
    "        train_status = train_engine.train_one_epoch(\n",
    "            model          = model, \n",
    "            data_loader    = fold_data_dict[fold_idx]['dataloader_dict']['train'], \n",
    "            loss_fn        = CFG.loss_fn, \n",
    "            device         = CFG.device, \n",
    "            amp_scaler     = CFG.amp_scaler, \n",
    "            optimizer      = optimizer, \n",
    "            clip_grad_norm = CFG.clip_grad_norm,\n",
    "            scheduler_lr   = scheduler_dict['lr'], \n",
    "            verbose        = True,\n",
    "        )\n",
    "        train_metrics = utils.classification_metrics(\n",
    "            y                = train_status['labels'], \n",
    "            y_pred           = train_status['logits'], \n",
    "            activation_fn    = True, \n",
    "            mode             = 'multilabel',\n",
    "            threshold_method = 'youden'\n",
    "        )\n",
    "        train_metrics['avg']['loss'] = train_status['loss']\n",
    "        monitor = f\"| TRN-Avg. | loss : {train_metrics['avg']['loss']:.3f}, AUROC : {train_metrics['avg']['AUROC']:.2f}, AUPRC : {train_metrics['avg']['AUPRC']:.2f}\"\n",
    "        print(monitor)\n",
    "        \n",
    "\n",
    "        #--- Model Validation ---#\n",
    "        if epoch % CFG.valid_interval == 0:\n",
    "            valid_status = train_engine.evaluate_one_epoch(\n",
    "                model          = model, \n",
    "                data_loader    = fold_data_dict[fold_idx]['dataloader_dict']['val'], \n",
    "                loss_fn        = CFG.loss_fn, \n",
    "                device         = CFG.device, \n",
    "                verbose        = True,\n",
    "            )\n",
    "            valid_metrics = utils.classification_metrics(\n",
    "                y                = valid_status['labels'], \n",
    "                y_pred           = valid_status['logits'], \n",
    "                activation_fn    = True, \n",
    "                mode             = 'multilabel',\n",
    "                threshold_method = 'youden'\n",
    "            )\n",
    "            valid_metrics['avg']['loss'] = valid_status['loss']\n",
    "            monitor = f\"| VAL-Avg. | loss : {valid_metrics['avg']['loss']:.3f}, AUROC : {valid_metrics['avg']['AUROC']:.3f}, AUPRC : {valid_metrics['avg']['AUPRC']:.3f}\"\n",
    "            print(monitor)\n",
    "\n",
    "\n",
    "            #--- Record training log ---#\n",
    "            BEST_RECORD_DICT['record_df'] = utils.history_recording(\n",
    "                record_df       = BEST_RECORD_DICT['record_df'], \n",
    "                epoch           = epoch, \n",
    "                train_metrics   = train_metrics, \n",
    "                valid_metrics   = valid_metrics,\n",
    "                save_path       = os.path.join(model_fold_path, 'learning_history.csv'), \n",
    "            )\n",
    "            utils.learning_curve_recording(\n",
    "                record_df         = BEST_RECORD_DICT['record_df'], \n",
    "                save_path         = os.path.join(model_fold_path, 'learning_curve.png'), \n",
    "                show              = False                \n",
    "            )\n",
    "\n",
    "            #--- Helper: 저장 함수 ---#\n",
    "            def maybe_save_best(metric_key: str, is_better: bool):\n",
    "                if is_better:\n",
    "                    ckpt_path_key = f'best_{metric_key}_ckp_path'\n",
    "                    old_ckpt = BEST_RECORD_DICT[ckpt_path_key]\n",
    "                    if old_ckpt and os.path.exists(old_ckpt) and CFG.model_auto_remove:\n",
    "                        os.remove(old_ckpt)\n",
    "                    model_name = f\"Best_{metric_key}-Ep_{epoch}-Lo_{valid_metrics['avg']['loss']:.3f}\"\n",
    "                    model_name += f\"-M0_{valid_metrics['avg']['AUROC']:.3f}-M1_{valid_metrics['avg']['AUPRC']:.3f}\"\n",
    "                    new_ckpt = os.path.join(model_fold_path, model_name + '.pth')\n",
    "                    utils.ModelSave(new_ckpt, epoch, model, optimizer, scheduler_dict['lr'])\n",
    "                    BEST_RECORD_DICT[ckpt_path_key] = new_ckpt\n",
    "                    BEST_RECORD_DICT[f'best_{metric_key}'] = valid_metrics['avg'][metric_key]\n",
    "\n",
    "            # Check improvements\n",
    "            improved = {\n",
    "                'loss': valid_metrics['avg']['loss'] < BEST_RECORD_DICT['best_loss'],\n",
    "                'AUROC': valid_metrics['avg']['AUROC'] > BEST_RECORD_DICT['best_AUROC'],\n",
    "                'AUPRC': valid_metrics['avg']['AUPRC'] > BEST_RECORD_DICT['best_AUPRC'],\n",
    "            }\n",
    "            if any(improved.values()):\n",
    "                print(\"*** Best Record! ***\")\n",
    "                for key, flag in improved.items():\n",
    "                    if flag:\n",
    "                        print(f\"- Improved {key}: {BEST_RECORD_DICT.get(f'best_{key}', float('nan')):.4f} → {valid_metrics['avg'][key]:.4f}\")\n",
    "                if improved['loss']:\n",
    "                    BEST_RECORD_DICT['best_loss'] = valid_status['loss']\n",
    "                    maybe_save_best('loss', True)\n",
    "                maybe_save_best('AUROC', improved['AUROC'])\n",
    "                maybe_save_best('AUPRC', improved['AUPRC'])\n",
    "\n",
    "            # Early stopping\n",
    "            monitor_value = valid_metrics['avg']['loss'] if CFG.early_stopping_mode == 'min' else valid_metrics['avg']['AUROC']\n",
    "            early_stopping(monitor_value)\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping triggered.\"); break\n",
    "        \n",
    "        torch.cuda.empty_cache()        \n",
    "        # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate at Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_624759/3834226691.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckp = torch.load(path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model name : MAE_1D_250409_v3\n",
      "seq_length 2560, in_channels 12, patch_size 32, embed_dim 768, token_len 80, \n",
      "model was loaded from '/home/bgk/macai-model-experimental/checkpoint/Step1-TRN_VAL-0526/Best_loss-Ep_550-Lo_0.0020.pth'\n",
      "Loaded: /home/bgk/macai-model-experimental/_kimbg_code/SynAI_v2/outputs/checkpoint/CL_step3-TRN-MacAI_v1_2-0822/0fold/Best_AUPRC-Ep_2-Lo_0.462-M0_0.758-M1_0.421.pth\n",
      "model name : MAE_1D_250409_v3\n",
      "seq_length 2560, in_channels 12, patch_size 32, embed_dim 768, token_len 80, \n",
      "model was loaded from '/home/bgk/macai-model-experimental/checkpoint/Step1-TRN_VAL-0526/Best_loss-Ep_550-Lo_0.0020.pth'\n",
      "Loaded: /home/bgk/macai-model-experimental/_kimbg_code/SynAI_v2/outputs/checkpoint/CL_step3-TRN-MacAI_v1_2-0822/0fold/Best_AUROC-Ep_2-Lo_0.462-M0_0.758-M1_0.421.pth\n",
      "model name : MAE_1D_250409_v3\n",
      "seq_length 2560, in_channels 12, patch_size 32, embed_dim 768, token_len 80, \n",
      "model was loaded from '/home/bgk/macai-model-experimental/checkpoint/Step1-TRN_VAL-0526/Best_loss-Ep_550-Lo_0.0020.pth'\n",
      "Loaded: /home/bgk/macai-model-experimental/_kimbg_code/SynAI_v2/outputs/checkpoint/CL_step3-TRN-MacAI_v1_2-0822/0fold/Best_loss-Ep_2-Lo_0.462-M0_0.758-M1_0.421.pth\n"
     ]
    }
   ],
   "source": [
    "def load_models(model_paths, device, model_fn, model_info):\n",
    "    models = []\n",
    "    for path in sorted(model_paths):\n",
    "        ckp = torch.load(path, map_location=device)\n",
    "        model = model_fn(model_info).to(device)\n",
    "        model.load_state_dict(ckp['model_state_dict'])\n",
    "        models.append({'path': path, 'model': model})\n",
    "        print(f\"Loaded: {path}\")\n",
    "    return models\n",
    "\n",
    "models_dict = {}\n",
    "for fold_idx, target_fold in enumerate(CFG.target_fold_list):\n",
    "    model_fold_path = os.path.join(CFG.model_save_path, f'{target_fold}fold')\n",
    "    if CFG.model_auto_remove:\n",
    "        model_paths = sorted(glob(os.path.join(model_fold_path, 'Be*.pth')))\n",
    "    else:\n",
    "        model_paths = sorted(glob(os.path.join(model_fold_path, '*loss*.pth')))[-1:]\n",
    "    models = load_models(model_paths, CFG.device, CFG.model_architecture, CFG.model_info)\n",
    "    models_dict[fold_idx] = models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_and_collect_probs(models, dataloader, device):\n",
    "    probs_list = []\n",
    "    for model_dict in models:\n",
    "        logits, all_labels = train_engine.only_inference(model_dict['model'], dataloader, device)\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "        name = os.path.basename(model_dict['path']).split('-')[0].split('_')[-1]\n",
    "        probs_list.append({'name': name, 'probs': probs})\n",
    "    return probs_list, all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:09<00:00,  1.21it/s]\n",
      "100%|██████████| 11/11 [00:09<00:00,  1.11it/s]\n",
      "100%|██████████| 11/11 [00:09<00:00,  1.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUROC</th>\n",
       "      <th>AUPRC</th>\n",
       "      <th>opt_thr</th>\n",
       "      <th>Accu</th>\n",
       "      <th>Sens</th>\n",
       "      <th>Prec</th>\n",
       "      <th>Spec</th>\n",
       "      <th>NPV</th>\n",
       "      <th>F1</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>Total_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.766292</td>\n",
       "      <td>0.293886</td>\n",
       "      <td>0.152588</td>\n",
       "      <td>0.706950</td>\n",
       "      <td>0.699422</td>\n",
       "      <td>0.201108</td>\n",
       "      <td>0.707742</td>\n",
       "      <td>0.957237</td>\n",
       "      <td>0.312392</td>\n",
       "      <td>3492.0</td>\n",
       "      <td>1442.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>363.0</td>\n",
       "      <td>5453.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.749905</td>\n",
       "      <td>0.548998</td>\n",
       "      <td>0.261230</td>\n",
       "      <td>0.674858</td>\n",
       "      <td>0.732589</td>\n",
       "      <td>0.449416</td>\n",
       "      <td>0.652506</td>\n",
       "      <td>0.863055</td>\n",
       "      <td>0.557082</td>\n",
       "      <td>2565.0</td>\n",
       "      <td>1366.0</td>\n",
       "      <td>407.0</td>\n",
       "      <td>1115.0</td>\n",
       "      <td>5453.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg</th>\n",
       "      <td>0.758098</td>\n",
       "      <td>0.421442</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690904</td>\n",
       "      <td>0.716005</td>\n",
       "      <td>0.325262</td>\n",
       "      <td>0.680124</td>\n",
       "      <td>0.910146</td>\n",
       "      <td>0.434737</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AUROC     AUPRC   opt_thr      Accu      Sens      Prec      Spec  \\\n",
       "0    0.766292  0.293886  0.152588  0.706950  0.699422  0.201108  0.707742   \n",
       "1    0.749905  0.548998  0.261230  0.674858  0.732589  0.449416  0.652506   \n",
       "avg  0.758098  0.421442       NaN  0.690904  0.716005  0.325262  0.680124   \n",
       "\n",
       "          NPV        F1      TN      FP     FN      TP  Total_N  \n",
       "0    0.957237  0.312392  3492.0  1442.0  156.0   363.0   5453.0  \n",
       "1    0.863055  0.557082  2565.0  1366.0  407.0  1115.0   5453.0  \n",
       "avg  0.910146  0.434737     NaN     NaN    NaN     NaN      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUROC</th>\n",
       "      <th>AUPRC</th>\n",
       "      <th>opt_thr</th>\n",
       "      <th>Accu</th>\n",
       "      <th>Sens</th>\n",
       "      <th>Prec</th>\n",
       "      <th>Spec</th>\n",
       "      <th>NPV</th>\n",
       "      <th>F1</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>Total_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7581</td>\n",
       "      <td>0.4214</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.6909</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.3253</td>\n",
       "      <td>0.6801</td>\n",
       "      <td>0.9101</td>\n",
       "      <td>0.4347</td>\n",
       "      <td>3028.5</td>\n",
       "      <td>1404.0</td>\n",
       "      <td>281.5</td>\n",
       "      <td>739.0</td>\n",
       "      <td>5453.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AUROC   AUPRC  opt_thr    Accu   Sens    Prec    Spec     NPV      F1  \\\n",
       "0  0.7581  0.4214   0.2069  0.6909  0.716  0.3253  0.6801  0.9101  0.4347   \n",
       "\n",
       "       TN      FP     FN     TP  Total_N  \n",
       "0  3028.5  1404.0  281.5  739.0   5453.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if 'val' in dataloader_dict.keys():\n",
    "    target_dataloader = dataloader_dict['val']\n",
    "    tmp_df = df_dict['val'].copy()\n",
    "\n",
    "    models = []\n",
    "    for k,v in models_dict.items():\n",
    "        models += v\n",
    "    probs_list, labels = infer_and_collect_probs(models, target_dataloader, CFG.device)\n",
    "    ensemble_probs = np.mean([d['probs'] for d in probs_list], axis=0)\n",
    "    prob_col = [i+'-prob' for i in CFG.target_cols['label']]\n",
    "    tmp_df[prob_col] = ensemble_probs\n",
    "    tmp_df.to_csv(os.path.join(CFG.model_save_path, 'EUMC-val-prob.csv'))\n",
    "\n",
    "    metrics = utils.classification_metrics(\n",
    "        y                = labels, \n",
    "        y_pred           = ensemble_probs, \n",
    "        activation_fn    = False, \n",
    "        mode             = 'multilabel',\n",
    "        threshold_method = 'youden'\n",
    "    )\n",
    "    metrics_df = pd.DataFrame(metrics).T\n",
    "    display(metrics_df)\n",
    "    metrics_df.index = CFG.target_cols['label'] + ['avg']\n",
    "    sub_idx = metrics_df.index[metrics_df.index.str.contains('14d')]\n",
    "    display(pd.DataFrame(metrics_df.loc[sub_idx, :].mean()).round(4).T)\n",
    "\n",
    "else:\n",
    "    print('No val set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Holdout Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:24<00:00,  1.23it/s]\n",
      "100%|██████████| 30/30 [00:23<00:00,  1.28it/s]\n",
      "100%|██████████| 30/30 [00:23<00:00,  1.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUROC</th>\n",
       "      <th>AUPRC</th>\n",
       "      <th>opt_thr</th>\n",
       "      <th>Accu</th>\n",
       "      <th>Sens</th>\n",
       "      <th>Prec</th>\n",
       "      <th>Spec</th>\n",
       "      <th>NPV</th>\n",
       "      <th>F1</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>Total_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.772515</td>\n",
       "      <td>0.276545</td>\n",
       "      <td>0.160767</td>\n",
       "      <td>0.707834</td>\n",
       "      <td>0.700581</td>\n",
       "      <td>0.193186</td>\n",
       "      <td>0.708557</td>\n",
       "      <td>0.959608</td>\n",
       "      <td>0.302859</td>\n",
       "      <td>9788.0</td>\n",
       "      <td>4026.0</td>\n",
       "      <td>412.0</td>\n",
       "      <td>964.0</td>\n",
       "      <td>15190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.738613</td>\n",
       "      <td>0.553140</td>\n",
       "      <td>0.350342</td>\n",
       "      <td>0.712377</td>\n",
       "      <td>0.593247</td>\n",
       "      <td>0.504237</td>\n",
       "      <td>0.761158</td>\n",
       "      <td>0.820464</td>\n",
       "      <td>0.545133</td>\n",
       "      <td>8203.0</td>\n",
       "      <td>2574.0</td>\n",
       "      <td>1795.0</td>\n",
       "      <td>2618.0</td>\n",
       "      <td>15190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg</th>\n",
       "      <td>0.755564</td>\n",
       "      <td>0.414842</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.710105</td>\n",
       "      <td>0.646914</td>\n",
       "      <td>0.348712</td>\n",
       "      <td>0.734857</td>\n",
       "      <td>0.890036</td>\n",
       "      <td>0.423996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AUROC     AUPRC   opt_thr      Accu      Sens      Prec      Spec  \\\n",
       "0    0.772515  0.276545  0.160767  0.707834  0.700581  0.193186  0.708557   \n",
       "1    0.738613  0.553140  0.350342  0.712377  0.593247  0.504237  0.761158   \n",
       "avg  0.755564  0.414842       NaN  0.710105  0.646914  0.348712  0.734857   \n",
       "\n",
       "          NPV        F1      TN      FP      FN      TP  Total_N  \n",
       "0    0.959608  0.302859  9788.0  4026.0   412.0   964.0  15190.0  \n",
       "1    0.820464  0.545133  8203.0  2574.0  1795.0  2618.0  15190.0  \n",
       "avg  0.890036  0.423996     NaN     NaN     NaN     NaN      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUROC</th>\n",
       "      <th>AUPRC</th>\n",
       "      <th>opt_thr</th>\n",
       "      <th>Accu</th>\n",
       "      <th>Sens</th>\n",
       "      <th>Prec</th>\n",
       "      <th>Spec</th>\n",
       "      <th>NPV</th>\n",
       "      <th>F1</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>Total_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7556</td>\n",
       "      <td>0.4148</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>0.7101</td>\n",
       "      <td>0.6469</td>\n",
       "      <td>0.3487</td>\n",
       "      <td>0.7349</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.424</td>\n",
       "      <td>8995.5</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>1103.5</td>\n",
       "      <td>1791.0</td>\n",
       "      <td>15190.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AUROC   AUPRC  opt_thr    Accu    Sens    Prec    Spec   NPV     F1  \\\n",
       "0  0.7556  0.4148   0.2556  0.7101  0.6469  0.3487  0.7349  0.89  0.424   \n",
       "\n",
       "       TN      FP      FN      TP  Total_N  \n",
       "0  8995.5  3300.0  1103.5  1791.0  15190.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if 'test' in dataloader_dict.keys():\n",
    "    target_dataloader = dataloader_dict['test']\n",
    "    tmp_df = df_dict['test'].copy()\n",
    "\n",
    "    models = []\n",
    "    for k,v in models_dict.items():\n",
    "        models += v\n",
    "    probs_list, labels = infer_and_collect_probs(models, target_dataloader, CFG.device)\n",
    "    ensemble_probs = np.mean([d['probs'] for d in probs_list], axis=0)\n",
    "    prob_col = [i+'-prob' for i in CFG.target_cols['label']]\n",
    "    tmp_df[prob_col] = ensemble_probs\n",
    "    tmp_df.to_csv(os.path.join(CFG.model_save_path, 'EUMC-test-prob.csv'))\n",
    "\n",
    "    metrics = utils.classification_metrics(\n",
    "        y                = labels, \n",
    "        y_pred           = ensemble_probs, \n",
    "        activation_fn    = False, \n",
    "        mode             = 'multilabel',\n",
    "        threshold_method = 'youden'\n",
    "    )\n",
    "    metrics_df = pd.DataFrame(metrics).T\n",
    "    display(metrics_df)\n",
    "    metrics_df.index = CFG.target_cols['label'] + ['avg']\n",
    "    sub_idx = metrics_df.index[metrics_df.index.str.contains('14d')]\n",
    "    display(pd.DataFrame(metrics_df.loc[sub_idx, :].mean()).round(4).T)\n",
    "\n",
    "else:\n",
    "    print('No test set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pub Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:36<00:00,  1.11it/s]\n",
      "100%|██████████| 40/40 [00:30<00:00,  1.33it/s]\n",
      "100%|██████████| 40/40 [00:31<00:00,  1.28it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUROC</th>\n",
       "      <th>AUPRC</th>\n",
       "      <th>opt_thr</th>\n",
       "      <th>Accu</th>\n",
       "      <th>Sens</th>\n",
       "      <th>Prec</th>\n",
       "      <th>Spec</th>\n",
       "      <th>NPV</th>\n",
       "      <th>F1</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>Total_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.731436</td>\n",
       "      <td>0.262902</td>\n",
       "      <td>0.139771</td>\n",
       "      <td>0.651695</td>\n",
       "      <td>0.697822</td>\n",
       "      <td>0.195699</td>\n",
       "      <td>0.646001</td>\n",
       "      <td>0.945414</td>\n",
       "      <td>0.305674</td>\n",
       "      <td>11535.0</td>\n",
       "      <td>6321.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>1538.0</td>\n",
       "      <td>20060.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.723555</td>\n",
       "      <td>0.440061</td>\n",
       "      <td>0.306152</td>\n",
       "      <td>0.672682</td>\n",
       "      <td>0.655604</td>\n",
       "      <td>0.389847</td>\n",
       "      <td>0.678040</td>\n",
       "      <td>0.862534</td>\n",
       "      <td>0.488948</td>\n",
       "      <td>10353.0</td>\n",
       "      <td>4916.0</td>\n",
       "      <td>1650.0</td>\n",
       "      <td>3141.0</td>\n",
       "      <td>20060.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg</th>\n",
       "      <td>0.727495</td>\n",
       "      <td>0.351481</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662188</td>\n",
       "      <td>0.676713</td>\n",
       "      <td>0.292773</td>\n",
       "      <td>0.662021</td>\n",
       "      <td>0.903974</td>\n",
       "      <td>0.397311</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AUROC     AUPRC   opt_thr      Accu      Sens      Prec      Spec  \\\n",
       "0    0.731436  0.262902  0.139771  0.651695  0.697822  0.195699  0.646001   \n",
       "1    0.723555  0.440061  0.306152  0.672682  0.655604  0.389847  0.678040   \n",
       "avg  0.727495  0.351481       NaN  0.662188  0.676713  0.292773  0.662021   \n",
       "\n",
       "          NPV        F1       TN      FP      FN      TP  Total_N  \n",
       "0    0.945414  0.305674  11535.0  6321.0   666.0  1538.0  20060.0  \n",
       "1    0.862534  0.488948  10353.0  4916.0  1650.0  3141.0  20060.0  \n",
       "avg  0.903974  0.397311      NaN     NaN     NaN     NaN      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUROC</th>\n",
       "      <th>AUPRC</th>\n",
       "      <th>opt_thr</th>\n",
       "      <th>Accu</th>\n",
       "      <th>Sens</th>\n",
       "      <th>Prec</th>\n",
       "      <th>Spec</th>\n",
       "      <th>NPV</th>\n",
       "      <th>F1</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>Total_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7275</td>\n",
       "      <td>0.3515</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.6622</td>\n",
       "      <td>0.6767</td>\n",
       "      <td>0.2928</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.3973</td>\n",
       "      <td>10944.0</td>\n",
       "      <td>5618.5</td>\n",
       "      <td>1158.0</td>\n",
       "      <td>2339.5</td>\n",
       "      <td>20060.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AUROC   AUPRC  opt_thr    Accu    Sens    Prec   Spec    NPV      F1  \\\n",
       "0  0.7275  0.3515    0.223  0.6622  0.6767  0.2928  0.662  0.904  0.3973   \n",
       "\n",
       "        TN      FP      FN      TP  Total_N  \n",
       "0  10944.0  5618.5  1158.0  2339.5  20060.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if 'pub_test' in dataloader_dict.keys():\n",
    "    target_dataloader = dataloader_dict['pub_test']\n",
    "    tmp_df = df_dict['pub_test'].copy()\n",
    "\n",
    "    models = []\n",
    "    for k,v in models_dict.items():\n",
    "        models += v\n",
    "    probs_list, labels = infer_and_collect_probs(models, target_dataloader, CFG.device)\n",
    "    ensemble_probs = np.mean([d['probs'] for d in probs_list], axis=0)\n",
    "    prob_col = [i+'-prob' for i in CFG.target_cols['label']]\n",
    "    tmp_df[prob_col] = ensemble_probs\n",
    "    tmp_df.to_csv(os.path.join(CFG.model_save_path, 'BID-test-prob.csv'))\n",
    "\n",
    "    metrics = utils.classification_metrics(\n",
    "        y                = labels, \n",
    "        y_pred           = ensemble_probs, \n",
    "        activation_fn    = False, \n",
    "        mode             = 'multilabel',\n",
    "        threshold_method = 'youden'\n",
    "    )\n",
    "    metrics_df = pd.DataFrame(metrics).T\n",
    "    display(metrics_df)\n",
    "    metrics_df.index = CFG.target_cols['label'] + ['avg']\n",
    "    sub_idx = metrics_df.index[metrics_df.index.str.contains('14d')]\n",
    "    display(pd.DataFrame(metrics_df.loc[sub_idx, :].mean()).round(4).T)\n",
    "\n",
    "else:\n",
    "    print('No pub_test set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SNUH Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:46<00:00,  1.37it/s]\n",
      "100%|██████████| 63/63 [00:44<00:00,  1.42it/s]\n",
      "100%|██████████| 63/63 [00:48<00:00,  1.31it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUROC</th>\n",
       "      <th>AUPRC</th>\n",
       "      <th>opt_thr</th>\n",
       "      <th>Accu</th>\n",
       "      <th>Sens</th>\n",
       "      <th>Prec</th>\n",
       "      <th>Spec</th>\n",
       "      <th>NPV</th>\n",
       "      <th>F1</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>Total_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.754971</td>\n",
       "      <td>0.310331</td>\n",
       "      <td>0.164551</td>\n",
       "      <td>0.694990</td>\n",
       "      <td>0.678884</td>\n",
       "      <td>0.225636</td>\n",
       "      <td>0.697084</td>\n",
       "      <td>0.943492</td>\n",
       "      <td>0.338701</td>\n",
       "      <td>19602.0</td>\n",
       "      <td>8518.0</td>\n",
       "      <td>1174.0</td>\n",
       "      <td>2482.0</td>\n",
       "      <td>31776.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.726095</td>\n",
       "      <td>0.500828</td>\n",
       "      <td>0.302490</td>\n",
       "      <td>0.653481</td>\n",
       "      <td>0.702816</td>\n",
       "      <td>0.415274</td>\n",
       "      <td>0.635299</td>\n",
       "      <td>0.852955</td>\n",
       "      <td>0.522071</td>\n",
       "      <td>14751.0</td>\n",
       "      <td>8468.0</td>\n",
       "      <td>2543.0</td>\n",
       "      <td>6014.0</td>\n",
       "      <td>31776.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg</th>\n",
       "      <td>0.740533</td>\n",
       "      <td>0.405580</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.674235</td>\n",
       "      <td>0.690850</td>\n",
       "      <td>0.320455</td>\n",
       "      <td>0.666191</td>\n",
       "      <td>0.898224</td>\n",
       "      <td>0.430386</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AUROC     AUPRC   opt_thr      Accu      Sens      Prec      Spec  \\\n",
       "0    0.754971  0.310331  0.164551  0.694990  0.678884  0.225636  0.697084   \n",
       "1    0.726095  0.500828  0.302490  0.653481  0.702816  0.415274  0.635299   \n",
       "avg  0.740533  0.405580       NaN  0.674235  0.690850  0.320455  0.666191   \n",
       "\n",
       "          NPV        F1       TN      FP      FN      TP  Total_N  \n",
       "0    0.943492  0.338701  19602.0  8518.0  1174.0  2482.0  31776.0  \n",
       "1    0.852955  0.522071  14751.0  8468.0  2543.0  6014.0  31776.0  \n",
       "avg  0.898224  0.430386      NaN     NaN     NaN     NaN      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUROC</th>\n",
       "      <th>AUPRC</th>\n",
       "      <th>opt_thr</th>\n",
       "      <th>Accu</th>\n",
       "      <th>Sens</th>\n",
       "      <th>Prec</th>\n",
       "      <th>Spec</th>\n",
       "      <th>NPV</th>\n",
       "      <th>F1</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>Total_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7405</td>\n",
       "      <td>0.4056</td>\n",
       "      <td>0.2335</td>\n",
       "      <td>0.6742</td>\n",
       "      <td>0.6909</td>\n",
       "      <td>0.3205</td>\n",
       "      <td>0.6662</td>\n",
       "      <td>0.8982</td>\n",
       "      <td>0.4304</td>\n",
       "      <td>17176.5</td>\n",
       "      <td>8493.0</td>\n",
       "      <td>1858.5</td>\n",
       "      <td>4248.0</td>\n",
       "      <td>31776.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AUROC   AUPRC  opt_thr    Accu    Sens    Prec    Spec     NPV      F1  \\\n",
       "0  0.7405  0.4056   0.2335  0.6742  0.6909  0.3205  0.6662  0.8982  0.4304   \n",
       "\n",
       "        TN      FP      FN      TP  Total_N  \n",
       "0  17176.5  8493.0  1858.5  4248.0  31776.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if 'snuh_test' in dataloader_dict.keys():\n",
    "    target_dataloader = dataloader_dict['snuh_test']\n",
    "    tmp_df = df_dict['snuh_test'].copy()\n",
    "\n",
    "    models = []\n",
    "    for k,v in models_dict.items():\n",
    "        models += v\n",
    "    probs_list, labels = infer_and_collect_probs(models, target_dataloader, CFG.device)\n",
    "    ensemble_probs = np.mean([d['probs'] for d in probs_list], axis=0)\n",
    "    prob_col = [i+'-prob' for i in CFG.target_cols['label']]\n",
    "    tmp_df[prob_col] = ensemble_probs\n",
    "    tmp_df.to_csv(os.path.join(CFG.model_save_path, 'SNUH-test-prob.csv'))\n",
    "\n",
    "    metrics = utils.classification_metrics(\n",
    "        y                = labels, \n",
    "        y_pred           = ensemble_probs, \n",
    "        activation_fn    = False, \n",
    "        mode             = 'multilabel',\n",
    "        threshold_method = 'youden'\n",
    "    )\n",
    "    metrics_df = pd.DataFrame(metrics).T\n",
    "    display(metrics_df)\n",
    "    metrics_df.index = CFG.target_cols['label'] + ['avg']\n",
    "    sub_idx = metrics_df.index[metrics_df.index.str.contains('14d')]\n",
    "    display(pd.DataFrame(metrics_df.loc[sub_idx, :].mean()).round(4).T)\n",
    "\n",
    "else:\n",
    "    print('No snuh_test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "macai-trn-v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
